import cv2
import numpy as np
import imageio
import time
import mediapipe as mp

# 设置颜色范围
lower = np.array([25, 30, 110])
upper = np.array([80, 70, 180])

def generateSeedModel(img, contours, png_img_resized):
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > 700:
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                png_x = cx - (png_img_resized.shape[1] // 2)
                png_y = cy - (png_img_resized.shape[0] // 2)
                if png_x >= 0 and png_y >= 0 and png_x + png_img_resized.shape[1] <= img.shape[1] and png_y + png_img_resized.shape[0] <= img.shape[0]:
                    for c in range(0, 3):
                        img[png_y:png_y + png_img_resized.shape[0], png_x:png_x + png_img_resized.shape[1], c] = \
                            img[png_y:png_y + png_img_resized.shape[0], png_x:png_x + png_img_resized.shape[1], c] * (1 - png_img_resized[:, :, 3] / 255.0) + png_img_resized[:, :, c] * (png_img_resized[:, :, 3] / 255.0)

# Load the PNG image with transparency (RGBA)
png_img_path = r'C:\Users\User\Downloads\seed.png'
png_img = cv2.imread(png_img_path, cv2.IMREAD_UNCHANGED)
desired_width = 30
desired_height = 30
png_img_resized = cv2.resize(png_img, (desired_width, desired_height))

# Load the GIF image
gif_path = r'C:\Users\User\Downloads\duck.gif'
gif = imageio.mimread(gif_path)
gif = [cv2.cvtColor(img, cv2.COLOR_RGBA2BGRA) for img in gif]
gif_resized = [cv2.resize(img, (100, 100)) for img in gif]
gif_index = 0

# Load the center image
center_image_path = r'C:\Users\User\Downloads\oho1.png'  # Replace 'path_to_center_image.jpg' with your image path
center_image = cv2.imread(center_image_path)
center_image_resized = cv2.resize(center_image, (100, 100))

# Main loop to capture video from camera
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("Cannot open camera")
    exit()

# Create window to display the overlay image
cv2.namedWindow('Overlay')

# Initialize variables for the timer
color_detected = False
start_time = 0

# 初始化MediaPipe手部检测
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)

while True:
    ret, img = cap.read()
    if not ret:
        print("Cannot receive frame")
        break
    img = cv2.resize(img, (640, 360))

    if color_detected and time.time() - start_time >= 1: 
        # Display the GIF image
        overlay_img = np.zeros_like(img)
        gif_frame = gif_resized[gif_index]
        gif_index = (gif_index + 1) % len(gif_resized)

        center_x = (overlay_img.shape[1] - gif_frame.shape[1]) // 2 + 100
        center_y = (overlay_img.shape[0] - gif_frame.shape[0]) // 2

        for c in range(0, 3):
            overlay_img[center_y:center_y + gif_frame.shape[0], center_x:center_x + gif_frame.shape[1], c] = \
                overlay_img[center_y:center_y + gif_frame.shape[0], center_x:center_x + gif_frame.shape[1], c] * (1 - gif_frame[:, :, 3] / 255.0) + gif_frame[:, :, c] * (gif_frame[:, :, 3] / 255.0)

         # 在中心图片显示后，开始手部检测
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = hands.process(img_rgb)

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp.solutions.drawing_utils.draw_landmarks(
                    overlay_img, 
                    hand_landmarks, 
                    mp_hands.HAND_CONNECTIONS,
                    mp.solutions.drawing_utils.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                    mp.solutions.drawing_utils.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)
                )

        # Display the center image
        center_x = (overlay_img.shape[1] - center_image_resized.shape[1]) // 2
        center_y = (overlay_img.shape[0] - center_image_resized.shape[0]) // 2
        for c in range(0, 3):
            overlay_img[center_y:center_y + center_image_resized.shape[0], center_x:center_x + center_image_resized.shape[1], c] = \
                center_image_resized[:, :, c]

        cv2.imshow('Overlay', overlay_img)

    else:
        mask = cv2.inRange(img, lower, upper)
        result = cv2.bitwise_and(img, img, mask=mask)

        contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        overlay_img = np.zeros_like(img)
        generateSeedModel(overlay_img, contours, png_img_resized)

        if contours:
            if not color_detected:
                color_detected = True
                start_time = time.time()
        else:
            color_detected = False

        cv2.imshow('Overlay', overlay_img)

    key = cv2.waitKey(1)
    if key == ord('q'):
        cv2.waitKey(1)
        break

cap.release()
cv2.destroyAllWindows()