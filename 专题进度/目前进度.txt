import cv2
import numpy as np
import time
import mediapipe as mp

# 设置颜色范围
lower = np.array([25, 30, 110])
upper = np.array([80, 70, 180])

# 定义函数，将PNG图像叠加到图像上
def generateSeedModel(img, contours, png_img_resized):
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > 700:
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                png_x = cx - (png_img_resized.shape[1] // 2)
                png_y = cy - (png_img_resized.shape[0] // 2)
                if png_x >= 0 and png_y >= 0 and png_x + png_img_resized.shape[1] <= img.shape[1] and png_y + png_img_resized.shape[0] <= img.shape[0]:
                    for c in range(0, 3):
                        img[png_y:png_y + png_img_resized.shape[0], png_x:png_x + png_img_resized.shape[1], c] = \
                            img[png_y:png_y + png_img_resized.shape[0], png_x:png_x + png_img_resized.shape[1], c] * (1 - png_img_resized[:, :, 3] / 255.0) + png_img_resized[:, :, c] * (png_img_resized[:, :, 3] / 255.0)

# 初始化MediaPipe手部检测
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)

# 加载带有透明度的PNG图像（RGBA）并调整大小
def load_png_image(path, width, height):
    png_img = cv2.imread(path, cv2.IMREAD_UNCHANGED)
    return cv2.resize(png_img, (width, height))

png_img_resized = load_png_image(r'C:\Users\User\Downloads\seed.png', 30, 30)
png_overlay_resized = load_png_image(r'C:\Users\User\Downloads\seed.png', 100, 100)

# 初始化摄像头
def init_camera():
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        print("无法打开摄像头")
        exit()
    return cap

cap = init_camera()

# 创建窗口以显示最终叠加图像
cv2.namedWindow('Final Overlay', cv2.WINDOW_NORMAL)
cv2.setWindowProperty('Final Overlay', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

# 控制变量
show_center_image = False
delay_center_image = False
start_time = 0
color_detection_active = True

while True:
    ret, img = cap.read()
    if not ret:
        print("无法接收帧")
        break
    img = cv2.resize(img, (640, 360))

    if color_detection_active:
        mask = cv2.inRange(img, lower, upper)
        result = cv2.bitwise_and(img, img, mask=mask)
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if len(contours) > 0:
            show_center_image = True
            if not delay_center_image:
                delay_center_image = True
                start_time = time.time()

        overlay_img = np.zeros_like(img)
        generateSeedModel(overlay_img, contours, png_img_resized)
    else:
        overlay_img = np.zeros_like(img)

    if delay_center_image and time.time() - start_time >= 3:
        delay_center_image = False
        color_detection_active = False

    frame_height, frame_width, _ = overlay_img.shape
    overlay_x = (frame_width - 100) // 2
    overlay_y = (frame_height - 100) // 2

    alpha_channel = np.expand_dims(png_overlay_resized[:, :, 3], axis=2)
    alpha_channel = np.tile(alpha_channel, (1, 1, 3))

    if show_center_image and not delay_center_image:
        overlay_img[overlay_y:overlay_y + 100, overlay_x:overlay_x + 100, :] = \
            overlay_img[overlay_y:overlay_y + 100, overlay_x:overlay_x + 100, :] * (1 - alpha_channel / 255.0) + \
            png_overlay_resized[:, :, :3] * (alpha_channel / 255.0)
        
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = hands.process(img_rgb)

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp.solutions.drawing_utils.draw_landmarks(
                    overlay_img, 
                    hand_landmarks, 
                    mp_hands.HAND_CONNECTIONS,
                    mp.solutions.drawing_utils.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                    mp.solutions.drawing_utils.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)
                )

    cv2.imshow('Final Overlay', overlay_img)

    if cv2.waitKey(1) == ord('q'):
        cv2.waitKey(1)
        break

cap.release()
cv2.destroyAllWindows()
