import cv2
import numpy as np
import imageio
import time
import mediapipe as mp

# 设置颜色范围
lower = np.array([25, 30, 110])
upper = np.array([80, 70, 180])

def generateSeedModel(img, contours, png_img_resized):
    seed_model_shown = False
    for contour in contours:
        area = cv2.contourArea(contour)
        if area > 700:
            M = cv2.moments(contour)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"])
                cy = int(M["m01"] / M["m00"])
                png_x = cx - (png_img_resized.shape[1] // 2)
                png_y = cy - (png_img_resized.shape[0] // 2)
                if png_x >= 0 and png_y >= 0 and png_x + png_img_resized.shape[1] <= img.shape[1] and png_y + png_img_resized.shape[0] <= img.shape[0]:
                    for c in range(0, 3):
                        img[png_y:png_y + png_img_resized.shape[0], png_x:png_x + png_img_resized.shape[1], c] = \
                            img[png_y:png_y + png_img_resized.shape[0], png_x:png_x + png_img_resized.shape[1], c] * (1 - png_img_resized[:, :, 3] / 255.0) + png_img_resized[:, :, c] * (png_img_resized[:, :, 3] / 255.0)
                    seed_model_shown = True
    return seed_model_shown

# 加载带有透明度的PNG图像（RGBA）并调整大小
png_img_path = r'C:\Users\User\Downloads\seed.png'
png_img = cv2.imread(png_img_path, cv2.IMREAD_UNCHANGED)
desired_width = 30
desired_height = 30
png_img_resized = cv2.resize(png_img, (desired_width, desired_height))

# 加载GIF图像
gif_path = r'C:\Users\User\Downloads\下雨.gif'
gif = imageio.mimread(gif_path)
gif = [cv2.cvtColor(img, cv2.COLOR_RGBA2BGRA) for img in gif]
gif_resized = [cv2.resize(img, (100, 100)) for img in gif]

# 控制GIF的播放状态
play_gif = False
gif_index = 0
gif_play_count = 0  # 记录GIF播放的次数

# 加载中心图像
center_image_path = r'C:\Users\User\Downloads\oho2.png'
center_image = cv2.imread(center_image_path, cv2.IMREAD_UNCHANGED)
center_image_resized = cv2.resize(center_image, (100, 100))

# 加载新的图像
new_image1_path = r'C:\Users\User\Downloads\f22.png'
new_image1 = cv2.imread(new_image1_path, cv2.IMREAD_UNCHANGED)
new_image1_resized = cv2.resize(new_image1, (100, 100))

new_image2_path = r'C:\Users\User\Downloads\f33.png'
new_image2 = cv2.imread(new_image2_path, cv2.IMREAD_UNCHANGED)
new_image2_resized = cv2.resize(new_image2, (100, 100))

# 初始化MediaPipe手部检测
mp_hands = mp.solutions.hands
hands = mp_hands.Hands(static_image_mode=False, max_num_hands=2, min_detection_confidence=0.5, min_tracking_confidence=0.5)

# 开始捕获来自摄像头的视频
cap = cv2.VideoCapture(0)
if not cap.isOpened():
    print("无法打开摄像头")
    exit()

# 创建窗口以显示最终叠加图像
cv2.namedWindow('Final Overlay', cv2.WINDOW_NORMAL)
cv2.setWindowProperty('Final Overlay', cv2.WND_PROP_FULLSCREEN, cv2.WINDOW_FULLSCREEN)

# 初始化变量
color_detected = False
start_time = 0
show_center_image = False
delay_center_image = False
color_detection_active = True

# 初始化GIF位置
gif_initial_position = (270, 80)
gif_last_position = gif_initial_position
gif_attached = False

# 中心图像更改相关变量
center_image_change_start_time = None
center_image_elapsed_time = 0
center_image_changed_to_first = False
center_image_changed_to_second = False

while True:
    ret, img = cap.read()
    if not ret:
        print("无法接收帧")
        break
    img = cv2.resize(img, (640, 360))

    if color_detection_active:
        mask = cv2.inRange(img, lower, upper)
        result = cv2.bitwise_and(img, img, mask=mask)
        contours, hierarchy = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        overlay_img = np.zeros_like(img)
        seed_model_shown = generateSeedModel(overlay_img, contours, png_img_resized)
        if seed_model_shown:
            show_center_image = True
            if not delay_center_image:
                delay_center_image = True
                start_time = time.time()
    else:
        overlay_img = np.zeros_like(img)

    if delay_center_image and time.time() - start_time >= 3:
        delay_center_image = False
        color_detection_active = False

    if show_center_image and not delay_center_image:
        overlay_img = np.zeros_like(img)
        gif_frame = gif_resized[gif_index]

        # 显示GIF在手指末端或最后位置
        gif_x, gif_y = gif_last_position

        # 确保 GIF 框不超出图像边界
        gif_x = max(0, min(gif_x, overlay_img.shape[1] - gif_frame.shape[1]))
        gif_y = max(0, min(gif_y, overlay_img.shape[0] - gif_frame.shape[0]))

        # 叠加GIF图像
        for c in range(0, 3):
            overlay_img[gif_y:gif_y + gif_frame.shape[0], gif_x:gif_x + gif_frame.shape[1], c] = \
                overlay_img[gif_y:gif_y + gif_frame.shape[0], gif_x:gif_x + gif_frame.shape[1], c] * (1 - gif_frame[:, :, 3] / 255.0) + gif_frame[:, :, c] * (gif_frame[:, :, 3] / 255.0)

        # 手部检测
        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
        results = hands.process(img_rgb)

        hand_in_gif_area = False

        if results.multi_hand_landmarks:
            for hand_landmarks in results.multi_hand_landmarks:
                mp.solutions.drawing_utils.draw_landmarks(
                    overlay_img, 
                    hand_landmarks, 
                    mp_hands.HAND_CONNECTIONS,
                    mp.solutions.drawing_utils.DrawingSpec(color=(0, 255, 0), thickness=2, circle_radius=2),
                    mp.solutions.drawing_utils.DrawingSpec(color=(0, 0, 255), thickness=2, circle_radius=2)
                )

                for i in [8, 12, 16, 20]:  # 检测食指、中指、无名指和小指的末端
                    x = int(hand_landmarks.landmark[i].x * img.shape[1])
                    y = int(hand_landmarks.landmark[i].y * img.shape[0])
                    if gif_x - 10 < x < gif_x + gif_frame.shape[1] + 10 and gif_y - 10 < y < gif_y + gif_frame.shape[0] + 10:  # 增加容错范围
                        gif_attached = True
                        gif_last_position = (x - gif_frame.shape[1] // 2, y - gif_frame.shape[0] // 2)
                        hand_in_gif_area = True
                        break

        if not hand_in_gif_area:
            gif_attached = False

        if gif_attached:
            gif_index = (gif_index + 1) % len(gif_resized)
            if gif_index == 0:
                play_gif = False
                gif_play_count += 1  # 增加GIF播放次数

        # 检查gif与center_image的碰撞
        center_x = (overlay_img.shape[1] - center_image_resized.shape[1]) // 2 
        center_y = (overlay_img.shape[0] - center_image_resized.shape[0]) // 2 + 100
        if gif_x < center_x + center_image_resized.shape[1] and gif_x + gif_frame.shape[1] > center_x and gif_y < center_y + center_image_resized.shape[0] and gif_y + gif_frame.shape[0] > center_y:
            if center_image_change_start_time is None:
                center_image_change_start_time = time.time()
            else:
                center_image_elapsed_time += time.time() - center_image_change_start_time
                center_image_change_start_time = time.time()
        else:
            center_image_change_start_time = None
            center_image_elapsed_time = 0
            center_image_changed_to_first = False
            center_image_changed_to_second = False

        # 更改中心图像 并且累计时间
        if center_image_elapsed_time >= 3 and not center_image_changed_to_first:
            center_image_resized = new_image1_resized
            center_image_changed_to_first = True
        elif center_image_elapsed_time >= 7 and not center_image_changed_to_second:
            center_image_resized = new_image2_resized
            center_image_changed_to_second = True

        # 显示中心图像
        for c in range(0, 3):
            overlay_img[center_y:center_y + center_image_resized.shape[0], center_x:center_x + center_image_resized.shape[1], c] = \
                center_image_resized[:, :, c] * (center_image_resized[:, :, 3] / 255.0) + overlay_img[center_y:center_y + center_image_resized.shape[0], center_x:center_x + center_image_resized.shape[1], c] * (1 - center_image_resized[:, :, 3] / 255.0)

    cv2.imshow('Final Overlay', overlay_img)

    key = cv2.waitKey(1)
    if key == ord('q'):
        break

cap.release()
cv2.destroyAllWindows()
print(f"GIF播放次数: {gif_play_count}")
